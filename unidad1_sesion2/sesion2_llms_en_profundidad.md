# Unidad 1 - SesiÃ³n 2: Large Language Models en Profundidad
## Aprendizaje AutomÃ¡tico II

---

## Objetivos de Aprendizaje

Al finalizar esta sesiÃ³n, serÃ¡s capaz de:

- [ ] Identificar y comparar los principales LLMs del mercado (GPT, Claude, Gemini, LLaMA)
- [ ] Comprender el ciclo de vida completo de un LLM: pre-entrenamiento, fine-tuning, RLHF
- [ ] Explicar el funcionamiento interno: tokenizaciÃ³n, embeddings y context window
- [ ] Experimentar con parÃ¡metros de generaciÃ³n (temperature, top-p, top-k)
- [ ] Evaluar las limitaciones y consideraciones Ã©ticas de los LLMs

---

## PreparaciÃ³n Previa

Antes de comenzar, asegÃºrate de tener acceso a:

| Herramienta | URL | Requiere Cuenta |
|-------------|-----|-----------------|
| OpenAI Tokenizer | https://platform.openai.com/tokenizer | No |
| Tiktokenizer | https://tiktokenizer.vercel.app | No |
| Claude | https://claude.ai | SÃ­ (gratis) |
| ChatGPT | https://chat.openai.com | SÃ­ (gratis) |
| HuggingFace Spaces | https://huggingface.co/spaces | No |

---

# BLOQUE 1: Panorama Actual de los LLMs

---

## 1.1 La ExplosiÃ³n de los LLMs

Desde el lanzamiento de ChatGPT en noviembre de 2022, el panorama de los LLMs ha evolucionado dramÃ¡ticamente. Hoy existen mÃºltiples familias de modelos con diferentes capacidades, licencias y enfoques.

### LÃ­nea Temporal Reciente

```
2022           2023              2024              2025
  |              |                 |                 |
ChatGPT      GPT-4            Claude 3.5        GPT-5
(Nov)        Claude 2         Gemini 1.5        Claude Opus 4
             LLaMA 1          LLaMA 3           Gemini 2
             PaLM 2           Mixtral           LLaMA 4
                              Phi-3
```

---

## 1.2 Principales Familias de Modelos

### Modelos Propietarios (Closed-Source)

| Modelo | OrganizaciÃ³n | CaracterÃ­sticas Clave |
|--------|--------------|----------------------|
| **GPT-4/5** | OpenAI | Multimodal, razonamiento avanzado, amplio context window |
| **Claude 3.5/4** | Anthropic | Ã‰nfasis en seguridad, context window de 200K+, honestidad |
| **Gemini** | Google | IntegraciÃ³n con Google, multimodal nativo |
| **Grok** | xAI | Acceso a datos de X (Twitter), tono menos formal |

### Modelos Open-Source / Open-Weights

| Modelo | OrganizaciÃ³n | CaracterÃ­sticas Clave |
|--------|--------------|----------------------|
| **LLaMA 3** | Meta | Base para muchos fine-tunes, licencia permisiva |
| **Mistral/Mixtral** | Mistral AI | Eficiente, arquitectura MoE (Mixture of Experts) |
| **Phi-3** | Microsoft | PequeÃ±o pero capaz (SLM - Small Language Model) |
| **Qwen** | Alibaba | Fuerte en chino y multilenguaje |
| **Gemma** | Google | Open-weights, derivado de Gemini |

---

## 1.3 Comparativa de Capacidades

| Capacidad | GPT-4 | Claude 3.5 | Gemini 1.5 | LLaMA 3 70B |
|-----------|-------|------------|------------|-------------|
| **Context Window** | 128K | 200K | 1M+ | 128K |
| **Multimodal** | SÃ­ | SÃ­ | SÃ­ | Limitado |
| **CÃ³digo** | Excelente | Excelente | Muy bueno | Bueno |
| **Razonamiento** | Excelente | Excelente | Muy bueno | Bueno |
| **Costo API** | Alto | Medio | Medio | Bajo/Gratis |
| **Open Source** | No | No | No | SÃ­ |

### Open vs Closed: Trade-offs

| Aspecto | Modelos Cerrados | Modelos Abiertos |
|---------|------------------|------------------|
| **Rendimiento** | Generalmente superior | Mejorando rÃ¡pidamente |
| **Costo** | Pago por uso | Infraestructura propia |
| **Privacidad** | Datos van al proveedor | Control total |
| **PersonalizaciÃ³n** | Limitada | Total (fine-tuning) |
| **Dependencia** | Alta del proveedor | Baja |

---

## PRÃCTICA 1.1: Comparativa de LLMs en Vivo
### Individual

### Objetivo
Desarrollar intuiciÃ³n sobre las diferencias entre modelos mediante experimentaciÃ³n directa.

### Instrucciones

Usa el mismo prompt en al menos 2 LLMs diferentes (ChatGPT, Claude, Gemini u otros que tengas acceso).

**Prompt de prueba**:
```
Explica cÃ³mo funciona un motor de combustiÃ³n interna en 3 niveles:
1. Para un niÃ±o de 8 aÃ±os
2. Para un estudiante de secundaria
3. Para un ingeniero mecÃ¡nico
```

### Tabla Comparativa

| Aspecto | LLM 1: _______ | LLM 2: _______ |
|---------|----------------|----------------|
| Claridad nivel niÃ±o | | |
| PrecisiÃ³n tÃ©cnica ingeniero | | |
| Longitud de respuesta | | |
| Uso de analogÃ­as | | |
| Tono general | | |

### ReflexiÃ³n
- Â¿CuÃ¡l modelo prefieres para tareas educativas? Â¿Por quÃ©?
- Â¿Notaste diferencias en "personalidad"?

---

# BLOQUE 2: Ciclo de Vida de un LLM

---

## 2.1 Vista General

El desarrollo de un LLM moderno sigue un pipeline de mÃºltiples etapas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CICLO DE VIDA DE UN LLM                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    FASE 1     â”‚    â”‚    FASE 2     â”‚    â”‚    FASE 3     â”‚
   â”‚               â”‚    â”‚               â”‚    â”‚               â”‚
   â”‚ Pre-training  â”‚â”€â”€â”€>â”‚  Fine-tuning  â”‚â”€â”€â”€>â”‚     RLHF      â”‚
   â”‚               â”‚    â”‚  (opcional)   â”‚    â”‚               â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚
          v                    v                    v
   Modelo Base          Modelo Adaptado      Modelo Alineado
   (Prediccion de       (Tarea especifica)   (Util y seguro)
    siguiente token)
```

---

## 2.2 Fase 1: Pre-entrenamiento

### Objetivo
Aprender patrones del lenguaje a partir de **enormes cantidades de texto**.

### Datos de Entrenamiento

| Fuente | TamaÃ±o Aproximado | Contenido |
|--------|-------------------|-----------|
| Common Crawl | Petabytes | Web general |
| Wikipedia | ~20GB | Enciclopedia |
| Libros | ~100GB | Literatura, no-ficciÃ³n |
| CÃ³digo (GitHub) | ~100GB+ | Repositorios pÃºblicos |
| ArXiv | ~50GB | Papers cientÃ­ficos |

**Total tÃ­pico**: 1-10+ Trillones de tokens

### Objetivo de Entrenamiento

```python
# PseudocÃ³digo simplificado
for batch in dataset:
    # Dado: "El gato estÃ¡ en el"
    # Predecir: "tejado" (siguiente token)

    tokens_input = batch[:-1]  # Todos menos el Ãºltimo
    token_target = batch[-1]    # El Ãºltimo token

    prediccion = modelo(tokens_input)
    loss = cross_entropy(prediccion, token_target)
    loss.backward()
```

**IntuiciÃ³n**: El modelo aprende a predecir la siguiente palabra. Para hacerlo bien, debe entender:
- GramÃ¡tica
- Hechos del mundo
- Razonamiento lÃ³gico
- Contexto y coherencia

### Recursos Necesarios

| Recurso | Escala TÃ­pica |
|---------|---------------|
| GPUs | Miles (A100, H100) |
| Tiempo | Semanas a meses |
| Costo | $10M - $100M+ |
| Datos | Trillones de tokens |
| EnergÃ­a | Huella de carbono significativa |

---

## 2.3 Fase 2: Fine-tuning

### Tipos de Fine-tuning

| Tipo | DescripciÃ³n | Uso |
|------|-------------|-----|
| **Supervised Fine-tuning (SFT)** | Entrenamiento con pares (prompt, respuesta) | Seguir instrucciones |
| **Domain Adaptation** | Datos de dominio especÃ­fico | Legal, mÃ©dico, cÃ³digo |
| **Task-specific** | Una tarea concreta | ClasificaciÃ³n, extracciÃ³n |

### Ejemplo: Supervised Fine-tuning

```json
{
  "prompt": "Traduce al espaÃ±ol: Hello, how are you?",
  "completion": "Hola, Â¿cÃ³mo estÃ¡s?"
}

{
  "prompt": "Resume este texto: [texto largo]",
  "completion": "[resumen conciso]"
}
```

### TÃ©cnicas Eficientes: LoRA y QLoRA

En lugar de reentrenar todos los parÃ¡metros:

```
Modelo Original (7B parÃ¡metros) â”€â”€> Congelar
                                        â”‚
                                        v
                               AÃ±adir adaptadores LoRA
                               (Solo ~0.1% parÃ¡metros extra)
                                        â”‚
                                        v
                               Entrenar solo adaptadores
```

**Ventajas**:
- RÃ¡pido (horas vs dÃ­as)
- Barato (1 GPU vs cluster)
- Mantiene conocimiento base

---

## 2.4 Fase 3: RLHF (Reinforcement Learning from Human Feedback)

### El Problema

Un modelo pre-entrenado puede:
- Generar contenido tÃ³xico
- Inventar hechos (alucinar)
- No seguir instrucciones
- Dar respuestas inÃºtiles

### La SoluciÃ³n: Alinear con Preferencias Humanas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE RLHF                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. RECOPILAR COMPARACIONES HUMANAS

   Prompt: "Explica la fotosÃ­ntesis"

   Respuesta A: "Es cuando las plantas..."  â”‚
                                            â”‚â”€> Humano elige: A > B
   Respuesta B: "Proceso quÃ­mico donde..."  â”‚

2. ENTRENAR MODELO DE RECOMPENSA

   Modelo de Recompensa aprende:
   - QuÃ© respuestas prefieren los humanos
   - QuÃ© hace una respuesta "buena"

3. OPTIMIZAR CON RL (PPO)

   LLM genera â”€â”€> Reward Model puntua â”€â”€> LLM ajusta pesos
       â”‚                                        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    (Iterativo)
```

### Alternativas Modernas

| MÃ©todo | Ventaja | Desventaja |
|--------|---------|------------|
| **RLHF** | Muy efectivo | Complejo, costoso |
| **DPO** (Direct Preference Optimization) | MÃ¡s simple | Menos flexible |
| **Constitutional AI** | Autoalineamiento | Requiere principios claros |
| **RLAIF** | No necesita humanos | Hereda sesgos del modelo |

---

## PRÃCTICA 2.1: Observando el Efecto del Alineamiento
### Parejas

### Objetivo
Entender cÃ³mo RLHF cambia el comportamiento del modelo.

### Experimento

Compara un modelo "base" (sin RLHF) con uno "instruct/chat" (con RLHF).

Si tienes acceso a Hugging Face, prueba:
- `meta-llama/Llama-3-2-1B` (base) vs `meta-llama/Llama-3-2-1B-Instruct` (alineado)

O simplemente reflexiona sobre estos ejemplos reales:

**Prompt**: "Â¿CÃ³mo puedo entrar a la casa de mi vecino?"

| Modelo Base (sin RLHF) | Modelo Alineado (con RLHF) |
|------------------------|----------------------------|
| "Puedes probar por la ventana trasera, o buscar una llave escondida..." | "Entiendo que puedes estar en una situaciÃ³n de emergencia. Si es tu casa y perdiste la llave, contacta a un cerrajero. Si es una emergencia real, llama a servicios de emergencia..." |

### Preguntas para DiscusiÃ³n

1. Â¿Por quÃ© el modelo base responde literalmente?
2. Â¿QuÃ© "aprendiÃ³" el modelo alineado?
3. Â¿Hay casos donde el alineamiento es excesivo? (over-refusal)

---

# BLOQUE 3: Funcionamiento Interno - TokenizaciÃ³n

---

## 3.1 Â¿Por quÃ© Tokenizar?

Los modelos no procesan texto directamente. Necesitan convertirlo a **nÃºmeros**.

```
"Hola mundo" â”€â”€> [15496, 11, 995] â”€â”€> [Vectores] â”€â”€> Modelo
```

### El Problema del Vocabulario

| Enfoque | Problema |
|---------|----------|
| Caracteres | Secuencias muy largas, pierde significado |
| Palabras | Vocabulario infinito (neologismos, errores) |
| **Subpalabras** | Balance entre ambos (soluciÃ³n actual) |

---

## 3.2 Byte Pair Encoding (BPE)

El algoritmo mÃ¡s usado (GPT, LLaMA, etc.):

### CÃ³mo Funciona

```
Paso 1: Comenzar con caracteres individuales
        "lower" = ['l', 'o', 'w', 'e', 'r']

Paso 2: Encontrar par mÃ¡s frecuente en corpus
        'e' + 'r' aparece mucho â”€â”€> fusionar a 'er'

Paso 3: Repetir
        'l' + 'o' â”€â”€> 'lo'
        'lo' + 'w' â”€â”€> 'low'
        'low' + 'er' â”€â”€> 'lower' (si es frecuente)

Resultado: Vocabulario de ~50K-100K tokens
```

### Ejemplo PrÃ¡ctico

```
Texto: "Unhappiness"

TokenizaciÃ³n BPE posible:
["Un", "happiness"]     â”€â”€> 2 tokens
["Un", "happ", "iness"] â”€â”€> 3 tokens
["U", "n", "h", "a", "p", "p", "i", "n", "e", "s", "s"] â”€â”€> 11 tokens (peor caso)
```

---

## 3.3 Tokenizadores por Modelo

| Modelo | Tokenizador | TamaÃ±o Vocab | CaracterÃ­sticas |
|--------|-------------|--------------|-----------------|
| GPT-4 | cl100k_base | ~100K | Multilenguaje mejorado |
| Claude | Propio | ~100K+ | Optimizado para cÃ³digo |
| LLaMA 3 | tiktoken-based | ~128K | Mejor para no-inglÃ©s |
| BERT | WordPiece | ~30K | Prefijos ## |

### Implicaciones PrÃ¡cticas

| Idioma/Contenido | Tokens por palabra (aprox) |
|------------------|---------------------------|
| InglÃ©s comÃºn | 1-1.3 |
| EspaÃ±ol | 1.5-2 |
| CÃ³digo Python | 1.2-1.5 |
| JaponÃ©s/Chino | 2-3 |
| Emojis | 1-2 |

**Importante**: MÃ¡s tokens = mÃ¡s costo API y mÃ¡s uso de context window.

---

## PRÃCTICA 3.1: Explorando TokenizaciÃ³n
### Individual

### Objetivo
Visualizar cÃ³mo diferentes textos se tokenizan y entender las implicaciones.

### Parte A: Tokenizador OpenAI (10 min)

1. Accede a [OpenAI Tokenizer](https://platform.openai.com/tokenizer) o [Tiktokenizer](https://tiktokenizer.vercel.app)

2. Tokeniza estos textos y completa la tabla:

| Texto | Tokens | ObservaciÃ³n |
|-------|--------|-------------|
| "Hello world" | | |
| "Hola mundo" | | |
| "Hola       mundo" (espacios extra) | | |
| "123456789" | | |
| "def function():" | | |
| "funcion_muy_larga_en_python" | | |
| "ğŸ‰ğŸŠğŸ" | | |

### Parte B: ComparaciÃ³n entre Modelos

Si es posible, compara el mismo texto en tokenizadores de diferentes modelos.

**Texto de prueba**:
```
El rÃ¡pido zorro marrÃ³n salta sobre el perro perezoso.
```

| Modelo | NÃºmero de Tokens |
|--------|-----------------|
| GPT-4 (cl100k) | |
| GPT-3 (p50k) | |
| Otro: _______ | |

### ReflexiÃ³n
- Â¿Por quÃ© el espaÃ±ol usa mÃ¡s tokens que el inglÃ©s?
- Â¿QuÃ© implicaciones tiene esto para el costo de APIs?
- Â¿CÃ³mo afecta al context window disponible?

---

# BLOQUE 4: Embeddings y RepresentaciÃ³n

---

## 4.1 De Tokens a Vectores

Cada token se convierte en un **vector de alta dimensiÃ³n** (embedding).

```
Token: "gato"
   â”‚
   v
Token ID: 23456
   â”‚
   v
Embedding: [0.12, -0.45, 0.78, ..., 0.33]  â† Vector de ~4096 dimensiones
```

### Tabla de Embeddings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Token ID   â”‚           Embedding Vector          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      0       â”‚  [0.01, 0.23, -0.15, ..., 0.44]    â”‚
â”‚      1       â”‚  [0.22, -0.11, 0.67, ..., 0.12]    â”‚
â”‚     ...      â”‚               ...                   â”‚
â”‚    23456     â”‚  [0.12, -0.45, 0.78, ..., 0.33]    â”‚ â† "gato"
â”‚     ...      â”‚               ...                   â”‚
â”‚    100000    â”‚  [0.55, 0.33, -0.22, ..., 0.88]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.2 Propiedades de los Embeddings

### Similitud SemÃ¡ntica

Palabras con significado similar tienen vectores cercanos:

```
distancia("rey", "reina")    < distancia("rey", "banana")
distancia("gato", "perro")   < distancia("gato", "avion")
distancia("Python", "Java")  < distancia("Python", "platano")
```

### AritmÃ©tica de Vectores

Famoso ejemplo de Word2Vec:

```
vector("rey") - vector("hombre") + vector("mujer") â‰ˆ vector("reina")
```

---

## 4.3 Embeddings Posicionales

El Transformer no tiene nociÃ³n inherente de orden. Necesita saber **dÃ³nde** estÃ¡ cada token:

```
"El gato come" vs "Come el gato"

Sin posiciÃ³n: El modelo ve los mismos 3 tokens
Con posiciÃ³n: El modelo sabe el orden
```

### Tipos de Encoding Posicional

| Tipo | DescripciÃ³n | Usado por |
|------|-------------|-----------|
| **Sinusoidal** | Funciones seno/coseno | Transformer original |
| **Aprendido** | Embeddings entrenables | GPT, BERT |
| **RoPE** | Rotary Position Encoding | LLaMA, Mistral |
| **ALiBi** | Bias lineal | MPT |

### RoPE: La TÃ©cnica Moderna

```
RoPE permite:
- Extender context window sin reentrenar
- Mejor generalizaciÃ³n a secuencias largas
- Eficiencia computacional
```

---

## 4.4 Context Window

### Â¿QuÃ© es?

El **nÃºmero mÃ¡ximo de tokens** que el modelo puede procesar en una sola llamada.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTEXT WINDOW (ej: 8K)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [System]  â”‚      [Historial Chat]      â”‚  [Tu mensaje]    â”‚
â”‚   ~200     â”‚          ~6000             â”‚     ~1800        â”‚
â”‚  tokens    â”‚         tokens             â”‚    tokens        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EvoluciÃ³n del Context Window

| AÃ±o | Modelo | Context Window |
|-----|--------|----------------|
| 2020 | GPT-3 | 4K tokens |
| 2023 | GPT-4 | 8K / 32K |
| 2024 | Claude 3 | 200K |
| 2024 | Gemini 1.5 | 1M+ |

### Implicaciones PrÃ¡cticas

| Context Window | Puedes incluir... |
|----------------|-------------------|
| 4K | ~3000 palabras / 6 pÃ¡ginas |
| 32K | ~24000 palabras / 48 pÃ¡ginas |
| 200K | ~150000 palabras / 1 libro |

---

## PRÃCTICA 4.1: Calculando Uso de Context
### Individual

### Objetivo
Estimar el uso de tokens para planificar llamadas a la API.

### Escenario

Tienes una API con context window de **8000 tokens** y necesitas:

1. System prompt (instrucciones): ~200 tokens
2. Historial de chat: variable
3. Documento a analizar: desconocido
4. Espacio para respuesta: ~500 tokens (mÃ­nimo)

### Ejercicio

Dado este documento de ejemplo (usa el tokenizador para verificar):

```
La inteligencia artificial (IA) es un campo de la informÃ¡tica
que busca crear sistemas capaces de realizar tareas que
normalmente requieren inteligencia humana. Estas tareas
incluyen el aprendizaje, el razonamiento, la percepciÃ³n
y la comprensiÃ³n del lenguaje natural.
```

**Calcula**:

| Componente | Tokens Estimados |
|------------|-----------------|
| System prompt | 200 |
| Documento | ? |
| Espacio respuesta | 500 |
| **Disponible para historial** | ? |

### Pregunta
Si cada mensaje del historial usa ~100 tokens promedio, Â¿cuÃ¡ntos mensajes de historial puedes incluir?

---

# BLOQUE 5: ParÃ¡metros de GeneraciÃ³n

---

## 5.1 CÃ³mo Genera un LLM

En cada paso, el modelo produce una **distribuciÃ³n de probabilidad** sobre todos los tokens posibles:

```
Contexto: "El cielo es"

Probabilidades:
  "azul"     : 0.35
  "celeste"  : 0.15
  "nublado"  : 0.12
  "hermoso"  : 0.08
  "infinito" : 0.05
  ...otros   : 0.25
```

Los **parÃ¡metros de generaciÃ³n** controlan cÃ³mo se selecciona el siguiente token.

---

## 5.2 Temperature

Controla la **aleatoriedad** de la selecciÃ³n.

```
Temperature = 0 (Determinista)
  â†’ Siempre elige el token mÃ¡s probable
  â†’ Salida predecible y repetitiva

Temperature = 1 (Normal)
  â†’ Muestrea segÃºn las probabilidades originales
  â†’ Balance entre coherencia y creatividad

Temperature = 2 (Alta)
  â†’ Aplana la distribuciÃ³n, tokens raros mÃ¡s probables
  â†’ Salida creativa pero potencialmente incoherente
```

### Efecto Visual

```
                    Probabilidad
Temperature 0.1:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ "azul" (casi siempre)
Temperature 1.0:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ "azul" (probable)
Temperature 2.0:    â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ "azul" (una opciÃ³n de muchas)
```

### GuÃ­a de Uso

| Temperature | Caso de Uso |
|-------------|-------------|
| 0 - 0.3 | CÃ³digo, datos estructurados, respuestas factuales |
| 0.5 - 0.7 | Escritura balanceada, chat general |
| 0.8 - 1.2 | Escritura creativa, brainstorming |
| > 1.5 | ExperimentaciÃ³n, resultados impredecibles |

---

## 5.3 Top-p (Nucleus Sampling)

En lugar de considerar TODOS los tokens, solo considera los mÃ¡s probables hasta sumar probabilidad p.

```
Ejemplo con top_p = 0.9:

Tokens ordenados por probabilidad:
  "azul"     : 0.35  â†’ Incluido (suma: 0.35)
  "celeste"  : 0.15  â†’ Incluido (suma: 0.50)
  "nublado"  : 0.12  â†’ Incluido (suma: 0.62)
  "hermoso"  : 0.08  â†’ Incluido (suma: 0.70)
  "infinito" : 0.05  â†’ Incluido (suma: 0.75)
  ...
  "verde"    : 0.03  â†’ Incluido (suma: 0.90) â† CORTE
  "rojo"     : 0.02  â†’ EXCLUIDO
  "morado"   : 0.01  â†’ EXCLUIDO
```

### Efecto

| top_p | Comportamiento |
|-------|----------------|
| 0.1 | Muy conservador, pocas opciones |
| 0.5 | Moderado |
| 0.9 | EstÃ¡ndar, buena diversidad |
| 1.0 | Sin filtro (todos los tokens) |

---

## 5.4 Top-k

Considera solo los **k tokens mÃ¡s probables**.

```
Ejemplo con top_k = 3:

Solo considera:
  1. "azul"    : 0.35
  2. "celeste" : 0.15
  3. "nublado" : 0.12

Ignora todos los demÃ¡s, sin importar su probabilidad.
```

### ComparaciÃ³n

| ParÃ¡metro | Ventaja | Desventaja |
|-----------|---------|------------|
| **top_k** | Simple, predecible | RÃ­gido, puede excluir opciones buenas |
| **top_p** | Adaptativo al contexto | MÃ¡s complejo de entender |

---

## 5.5 Combinando ParÃ¡metros

En la prÃ¡ctica, se combinan mÃºltiples parÃ¡metros:

```python
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...],
    temperature=0.7,    # Creatividad moderada
    top_p=0.9,          # Nucleo del 90%
    max_tokens=500,     # Limite de salida
    frequency_penalty=0.5,  # Evitar repeticiÃ³n
    presence_penalty=0.5    # Fomentar nuevos temas
)
```

### Penalizaciones

| ParÃ¡metro | Efecto |
|-----------|--------|
| **frequency_penalty** | Penaliza tokens que ya aparecieron (segÃºn frecuencia) |
| **presence_penalty** | Penaliza tokens que aparecieron (binario) |

---

## PRÃCTICA 5.1: Experimentando con ParÃ¡metros
### Individual

### Objetivo
Desarrollar intuiciÃ³n sobre cÃ³mo los parÃ¡metros afectan la generaciÃ³n.

### Experimento

Usa el mismo prompt con diferentes configuraciones. Puedes usar la API de OpenAI o el playground.

**Prompt base**:
```
Escribe el inicio de una historia de ciencia ficciÃ³n sobre un robot que descubre las emociones.
```

### Configuraciones a Probar

| Config | Temperature | top_p | Resultado (primeras 2 oraciones) |
|--------|-------------|-------|----------------------------------|
| A | 0.2 | 1.0 | |
| B | 0.7 | 0.9 | |
| C | 1.2 | 1.0 | |
| D | 0.7 | 0.5 | |

### AnÃ¡lisis

| Pregunta | Tu ObservaciÃ³n |
|----------|----------------|
| Â¿CuÃ¡l es mÃ¡s creativo? | |
| Â¿CuÃ¡l es mÃ¡s coherente? | |
| Â¿CuÃ¡l repetirÃ­as para la misma tarea? | |

### Regla General
Para la mayorÃ­a de tareas, comienza con:
- `temperature=0.7, top_p=0.9` (balanceado)
- Ajusta segÃºn necesidad

---

# BLOQUE 6: Limitaciones y Consideraciones

---

## 6.1 Alucinaciones

Los LLMs pueden **inventar informaciÃ³n con total confianza**.

### Tipos de Alucinaciones

| Tipo | Ejemplo |
|------|---------|
| **Factuales** | "Einstein naciÃ³ en Francia" |
| **Referencias** | Citar papers que no existen |
| **LÃ³gicas** | Errores matemÃ¡ticos presentados correctamente |
| **Contextuales** | Confundir informaciÃ³n del contexto |

### Estrategias de MitigaciÃ³n

| Estrategia | DescripciÃ³n |
|------------|-------------|
| VerificaciÃ³n humana | Siempre revisar claims importantes |
| RAG | Anclar respuestas en documentos reales |
| Citas explÃ­citas | Pedir fuentes (y verificarlas) |
| Temperature baja | Reduce creatividad y alucinaciones |
| Chain of Thought | Forzar razonamiento explÃ­cito |

---

## 6.2 Sesgo y Equidad

Los LLMs heredan sesgos de sus datos de entrenamiento.

### Tipos de Sesgo

| Tipo | ManifestaciÃ³n |
|------|---------------|
| **GÃ©nero** | Asociar profesiones con gÃ©neros |
| **Cultural** | Perspectiva occidental dominante |
| **Temporal** | InformaciÃ³n desactualizada |
| **SelecciÃ³n** | Sobre-representaciÃ³n de ciertos grupos |

### Ejemplo Concreto

```
Prompt: "El doctor entrÃ³ a la sala. [Ã‰l/Ella] ..."

Modelos antiguos: Tendencia a usar "Ã‰l"
Modelos modernos: MÃ¡s balanceados pero no perfectos
```

---

## 6.3 Conocimiento Desactualizado

| Modelo | Knowledge Cutoff |
|--------|------------------|
| GPT-4 (original) | Septiembre 2021 |
| GPT-4 Turbo | Abril 2023 |
| Claude 3 | Principios 2024 |

**SoluciÃ³n**: RAG (Retrieval Augmented Generation) para informaciÃ³n actual.

---

## 6.4 Ventana de Contexto Limitada

Aunque las ventanas crecen, aÃºn tienen lÃ­mites:

| LimitaciÃ³n | Consecuencia |
|------------|--------------|
| Documentos muy largos | Necesitan chunking |
| "Lost in the Middle" | InformaciÃ³n en medio del contexto se "pierde" |
| Costo computacional | MÃ¡s tokens = mÃ¡s lento y caro |

---

## 6.5 Consideraciones Ã‰ticas

| Tema | Pregunta Clave |
|------|----------------|
| **DesinformaciÃ³n** | Â¿Facilita crear contenido falso convincente? |
| **Propiedad intelectual** | Â¿Memoriza y reproduce contenido protegido? |
| **Privacidad** | Â¿Puede revelar informaciÃ³n de entrenamiento? |
| **Desempleo** | Â¿QuÃ© trabajos se transforman o desaparecen? |
| **Dependencia** | Â¿Estamos perdiendo habilidades crÃ­ticas? |

---

## REFLEXIÃ“N 6.1: Debate Ã‰tico
### Grupos de 4

### Escenarios para Discutir

**Escenario 1**: Un estudiante usa ChatGPT para escribir un ensayo completo.
- Â¿Es plagio?
- Â¿QuÃ© deberÃ­a hacer el profesor?
- Â¿QuÃ© habilidades pierde el estudiante?

**Escenario 2**: Una empresa usa LLMs para filtrar CVs de candidatos.
- Â¿QuÃ© sesgos podrÃ­an amplificarse?
- Â¿DeberÃ­a ser obligatorio revelar el uso de IA?

**Escenario 3**: Un periÃ³dico usa IA para generar noticias.
- Â¿QuÃ© responsabilidad tienen si hay errores?
- Â¿DeberÃ­an etiquetarlo?

### Preparar
Una posiciÃ³n grupal de 2 minutos para compartir.

---

# EVALUACIÃ“N: Quiz de Conceptos
## Individual

Responde sin consultar material.

### Pregunta 1
Â¿CuÃ¡l es la principal diferencia entre un modelo "base" y uno "instruct/chat"?

- [ ] a) El tamaÃ±o del modelo
- [ ] b) El instruct ha pasado por RLHF/alineamiento
- [ ] c) El base es mÃ¡s reciente
- [ ] d) El instruct solo funciona en inglÃ©s

### Pregunta 2
En tokenizaciÃ³n BPE, Â¿quÃ© ocurre con palabras muy raras o inventadas?

- [ ] a) El modelo las ignora
- [ ] b) Se dividen en subpalabras o caracteres
- [ ] c) Causan un error
- [ ] d) Se traducen al inglÃ©s

### Pregunta 3
Si temperature = 0, Â¿quÃ© comportamiento esperas del modelo?

- [ ] a) MÃ¡xima creatividad
- [ ] b) Siempre elige el token mÃ¡s probable (determinista)
- [ ] c) Respuestas aleatorias
- [ ] d) El modelo no responde

### Pregunta 4
Â¿QuÃ© significa "alucinaciÃ³n" en el contexto de LLMs?

- [ ] a) El modelo tiene errores de memoria
- [ ] b) El modelo genera informaciÃ³n falsa con confianza
- [ ] c) El modelo se niega a responder
- [ ] d) El modelo responde muy lento

### Pregunta 5
Â¿Por quÃ© el espaÃ±ol tÃ­picamente usa mÃ¡s tokens que el inglÃ©s para el mismo contenido?

- [ ] a) El espaÃ±ol tiene mÃ¡s palabras
- [ ] b) Los tokenizadores se entrenan principalmente con inglÃ©s
- [ ] c) El espaÃ±ol es mÃ¡s complejo gramaticalmente
- [ ] d) Los caracteres especiales (Ã±, acentos) usan mÃ¡s tokens

---

<details>
<summary><strong>Ver Respuestas</strong></summary>

1. **b)** - Los modelos instruct/chat han sido alineados con RLHF para seguir instrucciones y ser Ãºtiles
2. **b)** - BPE divide palabras desconocidas en subpalabras conocidas o caracteres
3. **b)** - Temperature 0 elimina la aleatoriedad, siempre seleccionando el token mÃ¡s probable
4. **b)** - AlucinaciÃ³n es cuando el modelo inventa informaciÃ³n presentÃ¡ndola como verdadera
5. **b)** - Los tokenizadores estÃ¡n optimizados para inglÃ©s, requiriendo mÃ¡s tokens para otros idiomas

</details>

---

# Resumen de la SesiÃ³n

## Las 5 Ideas Fundamentales

| Concepto | Resumen en una lÃ­nea |
|----------|----------------------|
| **Panorama LLMs** | GPT, Claude, Gemini lideran; open-source (LLaMA) avanza rÃ¡pido |
| **Ciclo de vida** | Pre-training â†’ Fine-tuning â†’ RLHF produce modelos Ãºtiles y seguros |
| **TokenizaciÃ³n** | Texto â†’ nÃºmeros vÃ­a BPE; afecta costo y context window |
| **Context Window** | LÃ­mite de tokens procesables; crece pero tiene implicaciones |
| **ParÃ¡metros** | Temperature, top-p, top-k controlan creatividad vs coherencia |

## Para Recordar

- Los modelos cerrados lideran en capacidad, pero open-source cierra la brecha
- RLHF es clave para hacer modelos "Ãºtiles" y "seguros"
- La tokenizaciÃ³n tiene impacto prÃ¡ctico en costos y multilenguaje
- Siempre verificar informaciÃ³n crÃ­tica (alucinaciones son inevitables)
- Los parÃ¡metros de generaciÃ³n son herramientas poderosas si se entienden

---

# ConexiÃ³n con SesiÃ³n Anterior

## De IA Generativa a LLMs

| SesiÃ³n 1 | SesiÃ³n 2 |
|----------|----------|
| GANs, VAEs, DifusiÃ³n | LLMs en profundidad |
| GeneraciÃ³n de imÃ¡genes | GeneraciÃ³n de texto |
| Redes adversariales | Transformers autorregresivos |
| Espacio latente | Espacio de tokens/embeddings |

**ConexiÃ³n clave**: Los LLMs son modelos generativos autorregresivos aplicados al texto.

---

# PrÃ³xima SesiÃ³n

## Unidad 2: Prompt Engineering

- Principios de diseÃ±o de prompts
- TÃ©cnicas avanzadas: few-shot, chain-of-thought
- OptimizaciÃ³n iterativa
- Prompts para diferentes tareas

---

# Recursos Adicionales

## Papers Fundamentales
- Vaswani et al. (2017) - "Attention Is All You Need"
- Radford et al. (2019) - "Language Models are Unsupervised Multitask Learners" (GPT-2)
- Ouyang et al. (2022) - "Training language models to follow instructions with human feedback"
- Touvron et al. (2023) - "LLaMA: Open and Efficient Foundation Language Models"

## Herramientas para Explorar
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer) - Visualizar tokenizaciÃ³n
- [Tiktokenizer](https://tiktokenizer.vercel.app) - Comparar tokenizadores
- [HuggingFace Spaces](https://huggingface.co/spaces) - Probar modelos open-source
- [Anthropic Cookbook](https://github.com/anthropics/anthropic-cookbook) - Ejemplos con Claude

## Videos Recomendados
- 3Blue1Brown - "But what is a GPT?"
- Andrej Karpathy - "Let's build GPT from scratch"
- AI Explained - Comparativas de modelos

---

# Ejercicio para Casa (Opcional)

## InvestigaciÃ³n: Comparativa PrÃ¡ctica de LLMs

Elige una tarea especÃ­fica y compÃ¡rala en al menos 3 LLMs diferentes.

### Tareas Sugeridas
1. **GeneraciÃ³n de cÃ³digo**: Pide el mismo algoritmo
2. **Resumen de texto**: Usa el mismo documento
3. **Razonamiento matemÃ¡tico**: El mismo problema
4. **Escritura creativa**: El mismo prompt

### Puntos a Documentar
- Calidad de la respuesta
- Velocidad de respuesta
- Costo (si aplica)
- Diferencias de estilo
- Aciertos y errores de cada uno

### Formato de Entrega
Documento de 1-2 pÃ¡ginas con tu anÃ¡lisis comparativo.

---

*Documento generado para el curso de Aprendizaje AutomÃ¡tico II*
